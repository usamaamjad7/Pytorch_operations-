{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Autograd_in_training.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM9JQ3qNQ7hvkQeAsNhyFZ6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"_uC4GTUJcxjb","executionInfo":{"status":"ok","timestamp":1622399313574,"user_tz":-300,"elapsed":756,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}}},"source":["import numpy as np\n","import torch\n","import torch.nn as nn"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KmG51kWTexoi"},"source":["# Single batch training"]},{"cell_type":"code","metadata":{"id":"TaM_cAAmcWm4","executionInfo":{"status":"ok","timestamp":1622399313575,"user_tz":-300,"elapsed":23,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}}},"source":["batch_size = 16\n","dim_in = 1000\n","hidden_size =100\n","dim_out =10\n","\n","class Tinymodel(torch.nn.Module):\n","    def __init__(self):\n","        super(Tinymodel,self).__init__()\n","\n","        self.layer1 = torch.nn.Linear(1000,100)\n","        self.relu = torch.nn.ReLU()\n","        self.layer2 = torch.nn.Linear(100,10)\n","        \n","    def forward(self,x):\n","        x = self.layer1(x)\n","        x = self.relu(x)\n","        x = self.layer2(x)\n","        return x\n","\n","some_input = torch.randn(batch_size,dim_in,requires_grad=True)\n","ideal_output = torch.randn(batch_size,dim_out,requires_grad=False)\n","\n","model = Tinymodel()"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jwoa1SqkfI7W"},"source":["look at the layers of the model we can examine the values of the weight but no gradient can computed yet"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mVEE3F7heoJW","executionInfo":{"status":"ok","timestamp":1622399313576,"user_tz":-300,"elapsed":21,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}},"outputId":"eea3fa27-4ed5-40ad-d220-70678b972ee2"},"source":["print(model.layer2.weight[0][0:10])\n","print(model.layer2.weight.grad)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["tensor([-0.0964, -0.0893, -0.0133,  0.0277, -0.0643, -0.0905,  0.0229,  0.0408,\n","         0.0910, -0.0329], grad_fn=<SliceBackward>)\n","None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"knv39Y4qf_n7"},"source":["# loss_func , prediction , optimizer"]},{"cell_type":"code","metadata":{"id":"8VcpLzy0gry6","executionInfo":{"status":"ok","timestamp":1622399313578,"user_tz":-300,"elapsed":19,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}}},"source":["import torch.optim"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AhvwRFjyfvZD","executionInfo":{"status":"ok","timestamp":1622399313580,"user_tz":-300,"elapsed":21,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}},"outputId":"8317b5ab-065f-4b3d-826a-4fd5325dbba2"},"source":["optimizer = torch.optim.SGD(model.parameters(),lr=0.001)\n","\n","prediction = model(some_input)\n","loss = (ideal_output-prediction).pow(2).sum()\n","print(loss)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["tensor(166.9617, grad_fn=<SumBackward0>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4LG2NHx4hE7P"},"source":["# loss.backward()"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wpylHvRogosc","executionInfo":{"status":"ok","timestamp":1622399313581,"user_tz":-300,"elapsed":18,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}},"outputId":"aadc4ef5-96d0-489c-9dfe-d033727a6cf7"},"source":["loss.backward()\n","print(model.layer2.weight[0][0:10])\n","print(model.layer2.weight.grad[0][0:10])\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["tensor([-0.0964, -0.0893, -0.0133,  0.0277, -0.0643, -0.0905,  0.0229,  0.0408,\n","         0.0910, -0.0329], grad_fn=<SliceBackward>)\n","tensor([ 1.3326,  0.2995, -0.3225,  0.9774,  0.8257,  2.6286,  0.6513,  3.2136,\n","         0.5124, -0.8974])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RixHdiTmjBF4"},"source":["The optimizer is responsible for updating model weight based on the computed Gradients"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T5zmJEOZhWJf","executionInfo":{"status":"ok","timestamp":1622399656272,"user_tz":-300,"elapsed":532,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}},"outputId":"74bb61ef-41ef-469d-e856-4522e2cd0f9d"},"source":["optimizer.step()\n","print(model.layer2.weight[0][0:10])\n","print(model.layer2.weight.grad[0][0:10])\n","# gradient can be computed but weight will remain unchanged..\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["tensor([-0.0991, -0.0899, -0.0127,  0.0258, -0.0659, -0.0957,  0.0216,  0.0343,\n","         0.0900, -0.0311], grad_fn=<SliceBackward>)\n","tensor([ 1.3326,  0.2995, -0.3225,  0.9774,  0.8257,  2.6286,  0.6513,  3.2136,\n","         0.5124, -0.8974])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OWDZwtXNkNP-"},"source":["One important thing about the process, After calling optimizer.step(). you need to call optimizer.zero_grad() , or else every time you can loss.backward()  the gardients on the learning weight will accumulate.."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KePSqIYMi3qw","executionInfo":{"status":"ok","timestamp":1622399825643,"user_tz":-300,"elapsed":512,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}},"outputId":"4e8a42d8-bcfd-472d-a3c9-8cd1f052fb96"},"source":["print(model.layer2.weight.grad[0][0:10])\n","\n","for i in range(0,5):\n","    prediction = model(some_input)\n","    loss = (ideal_output-prediction).pow(2).sum()\n","    loss.backward()\n","print(model.layer2.weight.grad[0][0:10])\n","optimizer.zero_grad()\n","print(model.layer2.weight.grad[0][0:10])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["tensor([ 1.3326,  0.2995, -0.3225,  0.9774,  0.8257,  2.6286,  0.6513,  3.2136,\n","         0.5124, -0.8974])\n","tensor([ 25.4164,  -0.9029, -10.5874,  11.2315,   4.7047,   7.9834,   6.7588,\n","         15.1513,  -0.4925,   5.1818])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k6d35-CUkLIe"},"source":[""],"execution_count":null,"outputs":[]}]}