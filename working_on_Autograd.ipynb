{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"working_on_Autograd.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOBMcK1tQQhwr/AO+bEnTLR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"I0bNwNe91Yg6"},"source":["# **Turning Autograd off and on**"]},{"cell_type":"markdown","metadata":{"id":"RG6H_OQF1gLW"},"source":["## requires_grad flag on tensor directly..."]},{"cell_type":"code","metadata":{"id":"1ZAol9pB1V7o","executionInfo":{"status":"ok","timestamp":1622393167408,"user_tz":-300,"elapsed":3898,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}}},"source":["import torch"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jOSkGGYE1twW","executionInfo":{"status":"ok","timestamp":1622393167409,"user_tz":-300,"elapsed":25,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}},"outputId":"a77b7b76-4192-4fc2-ccfb-cad649551f20"},"source":["a = torch.ones(2,3,requires_grad=True)\n","print(a)\n","\n","b1 = 2 * a\n","print(b1)\n","\n","a.requires_grad=False\n","b2 = a * 2\n","print(b2)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["tensor([[1., 1., 1.],\n","        [1., 1., 1.]], requires_grad=True)\n","tensor([[2., 2., 2.],\n","        [2., 2., 2.]], grad_fn=<MulBackward0>)\n","tensor([[2., 2., 2.],\n","        [2., 2., 2.]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TpDjGN7j239e"},"source":["the value of \"a\" and \"b1\" will be require_grad ... but the \"b2\" hai no require_grad.."]},{"cell_type":"markdown","metadata":{"id":"2aIi5oTa3yXQ"},"source":["# Autograd turned_off temporarily..."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ozbNnHJE2b09","executionInfo":{"status":"ok","timestamp":1622393167410,"user_tz":-300,"elapsed":16,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}},"outputId":"99e72f10-e4bc-4381-d3f4-70c1f2d0fa9b"},"source":["# use torch.no_grad()\n","a = torch.ones(2,3,requires_grad=True)*2\n","b = torch.ones(2,3,requires_grad=True)*3\n","\n","c1 = a + b\n","print(c1)\n","\n","with torch.no_grad():\n","    c2 = a + b\n","\n","print(c2)\n","c3 = a * b\n","print(c3)\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["tensor([[5., 5., 5.],\n","        [5., 5., 5.]], grad_fn=<AddBackward0>)\n","tensor([[5., 5., 5.],\n","        [5., 5., 5.]])\n","tensor([[6., 6., 6.],\n","        [6., 6., 6.]], grad_fn=<MulBackward0>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fGz_4uIT8N_D","executionInfo":{"status":"ok","timestamp":1622393167411,"user_tz":-300,"elapsed":13,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}},"outputId":"a3175a4c-7d85-4c81-af5d-2bdade4d5876"},"source":["def add_tensors1(x,y):\n","    return x+y\n","\n","@torch.no_grad()\n","def add_tensors2(x,y):\n","    return x + y\n","\n","a = torch.ones(2,3 , requires_grad=True)*2\n","b = torch.ones(2,3,requires_grad=True)*3\n","\n","\n","c1 = add_tensors1(a,b)\n","print(c1)\n","c2 = add_tensors2(a,b)\n","print(c2)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["tensor([[5., 5., 5.],\n","        [5., 5., 5.]], grad_fn=<AddBackward0>)\n","tensor([[5., 5., 5.],\n","        [5., 5., 5.]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2_aYlrgiLi90"},"source":["# detach()"]},{"cell_type":"code","metadata":{"id":"_SR4Vfmj9lh4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622393518884,"user_tz":-300,"elapsed":393,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}},"outputId":"69f4b89b-eca8-4724-a5c5-9b8f8a4d6cac"},"source":["x = torch.rand(5 , requires_grad = True)\n","y = x.detach()\n","\n","print(x)\n","print(y)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["tensor([0.0352, 0.0162, 0.4228, 0.4547, 0.9030], requires_grad=True)\n","tensor([0.0352, 0.0162, 0.4228, 0.4547, 0.9030])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"K8c-R3wzZiki"},"source":["# Autograd Profiler\n","\n","*   Autograd tracks every step of your computation in detail.\n","*   computation history combined with time information...\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E686boXbL2Y0","executionInfo":{"status":"ok","timestamp":1622396972119,"user_tz":-300,"elapsed":632,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}},"outputId":"8383a092-d63d-43ef-ab26-c05d2fb2a12c"},"source":["device = torch.device('cpu')\n","run_on_gpu = False\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","    run_on_gpu = True\n","x = torch.randn(2,3,requires_grad=True)\n","y = torch.rand(2,3,requires_grad=True)\n","z = torch.ones(2,3,requires_grad=True)\n","\n","with torch.autograd.profiler.profile(use_cuda= run_on_gpu) as prf:\n","    for _ in range(1000):\n","        z = (z / x)*y\n","\n","print(prf.key_averages().table(sort_by = \"self_cpu_time_total\"))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["---------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n","           Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n","---------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n","      aten::div        48.24%      13.483ms        50.65%      14.157ms      14.157us      14.032ms        50.49%      14.032ms      14.032us          1000  \n","      aten::mul        47.06%      13.153ms        49.35%      13.791ms      13.791us      13.761ms        49.51%      13.761ms      13.761us          1000  \n","    aten::empty         4.69%       1.311ms         4.69%       1.311ms       0.656us       0.000us         0.00%       0.000us       0.000us          2000  \n","---------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n","Self CPU time total: 27.948ms\n","Self CUDA time total: 27.793ms\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7zX_HrpUVwN1"},"source":[""],"execution_count":null,"outputs":[]}]}